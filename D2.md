## Service Containerization (Implementation & Deployment Decisions)

- ### Chosen approach to containerize must have services.

  1. Docker is used to containerize the services
  2. Docker compose is used to run multiple docker containers locally
  3. Every service got its on dockerfile, docker compose is used coordinate the services, docker compose runs containers based on directory

- ### Deployment workflow and CI/CD considerations.

  - Deployment [WIP]
    1. Kubernetes is used for deployment
    2. Kubernetes will be deployed in AWS using Amazon Elastic Kubernetes Service (EKS)
  - CI/CD [mainly CI]
    1. run lint for each service -> run test for each service[WIP], build for each service (Node.js) -> build dockerfile image -> push the images to docker hub

- ### Alignment with scalability and production readiness.

  - Implementation tech stack: language/runtime versions, package
    manager, framework; base image choice; Dockerfile strategy,
    dependency/security scanning, image tagging/versioning.

  ### Tech stack and Frameworks

  - Express.js with TypeScript (Due to its strong typing) (for all backend services)
  - Postgres (DB used by all backend services)
  - Prisma (Postgres integration for ORM)
  - YJS, CollabMonoca (collab service for real time coding)
  - NextJS, MUIMaterial with tailwind (Frontend)
  - Redis (Shared database among services)
  - RabbitMQ (Queue for async communication between services)

  ### Package manager

  - npm is used to handle the dependencies (prod and dev) in the backend, run scripts
  - pnpm is used in the frontend

  ### Base Image Choices

  | Service Type         | Base Image              | Reason                                 |
  | :------------------- | :---------------------- | :------------------------------------- |
  | **Node.js services** | `node:24-alpine`        | official image with minimal footprint. |
  | **Frontend**         | `node:20-alpine`        | Image suggested by next.js             |
  | **POSTGRES**         | `postgres`              | Official database image                |
  | **Redis**            | `redis`                 | Official database image                |
  | **RabbitMQ**         | `rabbitmq:4-management` | Official database image                |

  ### Image Tagging

  - peerprep docker private repo https://hub.docker.com/repository/docker/peerprep4/peerprep4/general
  - Tagging is peerprep4/peerprep4:tag where tag = service name
    - eg peerprep4/peerprep4:question_service

- Configuration & secrets: env vars, secret management (e.g.,
  SSM/Secrets Manager/K8s Secrets)

  - Using K8s secrets

- Networking & ingress: service-to-service comms, ingress/controller
  choice, ports, API gateway/ingress rules.

  - For api-gateway, using ngress NGINX Controller to act as reverse proxy to internal services

  - Networking, since k8s is being used, all the services (aka pods) will be in a ipCluster (internal private network), comms will be done through the network. Comms between service will be by their names set by the yaml file, k8s creates own ip address and does the DNS for the service name to ip-address.

  - Ports:

    - domain:3000 (frontend exposed to public)
    - domain:3001 (api-gateway expose to public)

    Ports after this does not matter anymore, I all use the same port because the service will be indenttied via serevice_name:port

    - domain:3002, 3003, 3004, 3005 (BE services private)
    - domain:3012, 3013, 3014 (Respective db for their servcies, matching service do not use postgres db)
    - domain:3015 (RabbitMQ)
    - domain:3016 (redis)

4. CI/CD & rollout: Discussed as above

5. Observability: health checks (liveness/readiness),

6. Scalability: using HPA, to set the min and max no. of pod instances

### Arc diagram for peerprep

![](/arc_dia.drawio.png)
